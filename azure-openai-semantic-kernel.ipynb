{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6943f2-e4c6-45e0-96f8-ff882ec32ff8",
   "metadata": {},
   "source": [
    "# Azure OpenAI and Semantic Kernel Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6116a418-7a82-4f89-ab1f-22cc526bced8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45bf976-c7a0-452a-bb1d-1cb06db44012",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "from semantic_kernel.connectors.ai.open_ai.services.azure_text_embedding import AzureTextEmbedding\n",
    "from semantic_kernel.connectors.memory.azure_cognitive_search import (\n",
    "    AzureCognitiveSearchMemoryStore,\n",
    ")\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.core_plugins.http_plugin import HttpPlugin\n",
    "from semantic_kernel.core_plugins.math_plugin import MathPlugin\n",
    "from semantic_kernel.core_plugins.sessions_python_tool.sessions_python_plugin import (\n",
    "    SessionsPythonTool,\n",
    ")\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "from semantic_kernel.core_plugins.text_plugin import TextPlugin\n",
    "from semantic_kernel.core_plugins.time_plugin import TimePlugin\n",
    "from semantic_kernel.functions import KernelArguments, kernel_function\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.volatile_memory_store import VolatileMemoryStore\n",
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe27f4-2950-4dfa-a6af-064d28df350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoints\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = \"gpt-4\"\n",
    "AZURE_OPENAI_ENDPOINT = \"https://XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "AZURE_OPENAI_API_KEY = \"XXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "AZURE_EMBEDDING_DEPLOYMENT_NAME = \"text-embedding-ada-002\"\n",
    "AZURE_EMBEDDING_ENDPOINT = \"https://XXXXXXXXXXXXXXXXXXXXXXXXXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8902f-eb73-4460-b313-b73dc17fb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize kernel\n",
    "kernel = Kernel()\n",
    "print(kernel.services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93e7ee-377b-499c-b34b-99f705d4bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add deployments to kernel\n",
    "chat_service_id = \"gpt-4\"\n",
    "azure_openai_chat_gpt35 = AzureChatCompletion(\n",
    "    service_id=chat_service_id,\n",
    "    deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    ")\n",
    "embedding_service_id = \"text-embedding-ada-002\"\n",
    "embedding_gen = AzureTextEmbedding(\n",
    "    service_id=embedding_service_id,\n",
    "    deployment_name=AZURE_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    endpoint=AZURE_EMBEDDING_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    ")\n",
    "kernel.add_service(azure_openai_chat_gpt35)\n",
    "kernel.add_service(embedding_gen)\n",
    "print(kernel.services)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5724b-10f3-4943-9fa6-a53d92aa689f",
   "metadata": {},
   "source": [
    "## Semantic Functions, Prompts, Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb18d67-16e5-4655-88e7-a428e14f3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process:\n",
    "# 1. prompt\n",
    "# 2. execution settings\n",
    "# 3. prompt template config (prompt + execution settings + inputs)\n",
    "# 4. add function (prompt template) to kernel\n",
    "# 5. invoke kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a87120-07f5-4525-bc9d-8834343a81bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "simple_prompt = \"\"\"\n",
    "You are an expert chat bot in answering questions and giving answers.\n",
    "###INSTRUCTIONS###\n",
    "***BE CONCISE, LESS IS MORE, USE 1 SENTENCE IF POSSIBLE***\n",
    "###OUTPUT FORMAT###\n",
    "Answer: ...\n",
    "+++++\n",
    "Answer the following in the style of {{$style}}: \n",
    "Question: {{$input}}\n",
    "+++++\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39f3fa-4508-41c8-bd38-ea573959d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution settings - option 1 - dictionary\n",
    "simple_execution_settings = {\"default\": {\"max_tokens\": 1000, \"temperature\": 0.7, \"top_p\": 0.6}}\n",
    "# execution settings - option 2 - AzureChatPromptExecutionSettings\n",
    "simple_execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=chat_service_id, max_tokens=1000, temperature=0.7, top_p=0.8\n",
    ")\n",
    "# execution settings - option 3 - from service id\n",
    "simple_execution_settings = kernel.get_prompt_execution_settings_from_service_id(chat_service_id)\n",
    "simple_execution_settings.max_tokens = 1000\n",
    "simple_execution_settings.temperature = 0.7\n",
    "simple_execution_settings.top_p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de4692-8050-4232-8693-c83f9da28c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template (prompt, inputs, and execution settings)\n",
    "simple_prompt_template_config = PromptTemplateConfig(\n",
    "    template=simple_prompt,\n",
    "    name=\"example-prompt-config\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"user input text\", is_required=True),\n",
    "        InputVariable(\n",
    "            name=\"style\",\n",
    "            description=\"answer style\",\n",
    "            default=\"professional\",\n",
    "            is_required=False,\n",
    "        ),\n",
    "    ],\n",
    "    execution_settings=simple_execution_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d824fa2-be57-4d00-ad1a-a250afb3c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add function to kernel\n",
    "question_function = kernel.add_function(\n",
    "    function_name=\"my_simple_question_function\",\n",
    "    plugin_name=\"my_simple_question_plugin\",\n",
    "    prompt_template_config=simple_prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00daf24d-93d7-429c-875f-62be7e590bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "input_text = \"Who is David Lee Roth?\"\n",
    "style_text = \"A Surfer Dude\"\n",
    "result = await kernel.invoke(question_function, KernelArguments(input=input_text, style=style_text))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac46b8-3b71-4474-a9de-e65f840a6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get multiple responses\n",
    "multiple_execution_settings = simple_execution_settings.copy()\n",
    "multiple_execution_settings.number_of_responses = 3\n",
    "results = await azure_openai_chat_gpt35.get_text_contents(\n",
    "    prompt=input_text, settings=multiple_execution_settings\n",
    ")\n",
    "for i, each in enumerate(results):\n",
    "    print(i + 1, each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb9e99-5eaa-4ac1-8638-b0461924d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text embedding\n",
    "await embedding_gen.generate_embeddings(\"David Lee Roth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2554bb3-a23d-4002-b0bf-4558b549505e",
   "metadata": {},
   "source": [
    "## Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066573e5-066f-460c-aa41-8e60e2664cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt with input and chat history\n",
    "history_prompt = \"\"\"\n",
    "You are a useful chat bot, be as helpful as possible to the user.\n",
    "###INSTRUCTIONS###\n",
    "***BE CONCISE, LESS IS MORE, USE 1 SENTENCE IF POSSIBLE***\n",
    "###CHAT HISTORY###\n",
    "Use the following chat history if useful: \n",
    "{{$history}}\n",
    "+++++\n",
    "Answer the following: \n",
    "Question: {{$input}}\n",
    "+++++\n",
    "\"\"\"\n",
    "history_execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=chat_service_id,\n",
    "    ai_model_id=\"gpt-4\",\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    ")\n",
    "history_prompt_template_config = PromptTemplateConfig(\n",
    "    template=history_prompt,\n",
    "    name=\"chat\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"user input\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"conversation history\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=history_execution_settings,\n",
    ")\n",
    "history_chat_function = kernel.add_function(\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"chatPlugin\",\n",
    "    prompt_template_config=history_prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b99d65-7b96-4e1f-94d9-ddb01a7c93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be459ee6-5dd8-479d-83c1-21b8e96946b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(input, chat_history):\n",
    "    answer = await kernel.invoke(\n",
    "        history_chat_function,\n",
    "        KernelArguments(input=input, history=chat_history),\n",
    "    )\n",
    "    print(f\"Chatbot: {answer}\")\n",
    "    chat_history.add_user_message(input)\n",
    "    chat_history.add_assistant_message(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e247ac0-0c06-4ddf-b565-13d929fdcb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"How many members have been in the band?\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9f74e-d5ad-4a92-8607-cb21ef4c32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"The band is Van Halen\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3da3e7-653d-4d5e-804c-4c95441bf82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"What instruments did each person play?\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca04aa-b68a-486a-800a-3d1b102d1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"What about Gary Cherone?\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62897b6-160e-46bc-aa75-66b4a666743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b373f-30c1-4bec-9dbc-1eba234fd8d7",
   "metadata": {},
   "source": [
    "## Memory, Vector Database Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf0687-2164-451b-80f3-34ebd00e3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp memory store\n",
    "memory = SemanticTextMemory(storage=VolatileMemoryStore(), embeddings_generator=embedding_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8e0c3-84dc-4876-8c1b-ea5069a094c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add plugin\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832a1ed-8f92-4fff-992b-4c5162354b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add information\n",
    "collection_id = \"temp\"\n",
    "await memory.save_information(collection=collection_id, id=\"info1\", text=\"Your brother is Mike\")\n",
    "await memory.save_information(collection=collection_id, id=\"info2\", text=\"Your sister is Lisa\")\n",
    "await memory.save_information(collection=collection_id, id=\"info3\", text=\"You made $100 in 2010\")\n",
    "await memory.save_information(collection=collection_id, id=\"info4\", text=\"You made $500 in 2020\")\n",
    "await memory.save_information(collection=collection_id, id=\"info4\", text=\"ND stands for Notre Dame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a6245-b84b-4ead-a6a4-5af157d17f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup information\n",
    "result = await memory.get(\"temp\", \"info1\")\n",
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486eea86-0a76-455f-8be7-9cbff003fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search\n",
    "questions = [\n",
    "    \"Who is my sister?\",\n",
    "    \"Who is my brother?\",\n",
    "    \"How much money did I make?\",\n",
    "    \"What is today's date?\",\n",
    "    \"Notre Dame\",\n",
    "]\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    result = await memory.search(collection_id, question, limit=3, min_relevance_score=0.8)\n",
    "    for each_result in result:\n",
    "        print(each_result.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec611e56-ec87-4144-97af-5ba6b1fe32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt with input and memory function (recall), will search for input in memory as context\n",
    "memory_prompt = \"\"\"\n",
    "You are a useful chat bot, be as helpful as possible to the user.\n",
    "###INSTRUCTIONS###\n",
    "***BE CONCISE, LESS IS MORE, USE 1 SENTANCE IF POSSIBLE***\n",
    "***DO NOT ANSWER QUESTION IF YOU ARE NOT 100% SURE***\n",
    "###MEMORY###\n",
    "Use the following information if useful: \n",
    "Context: {{recall $input}}\n",
    "Context: {{recall 'Notre Dame'}}\n",
    "+++++\n",
    "Answer the following: \n",
    "Question: {{$input}}\n",
    "+++++\n",
    "\"\"\"\n",
    "memory_prompt_template_config = PromptTemplateConfig(\n",
    "    template=memory_prompt,\n",
    "    execution_settings={\n",
    "        chat_service_id: kernel.get_service(chat_service_id).get_prompt_execution_settings_class()(\n",
    "            service_id=chat_service_id\n",
    "        )\n",
    "    },\n",
    ")\n",
    "chat_with_memory = kernel.add_function(\n",
    "    function_name=\"chat_with_memory\",\n",
    "    plugin_name=\"chat\",\n",
    "    prompt_template_config=memory_prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4fb85-8798-4b79-a0f8-005e24b7c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = await kernel.invoke(\n",
    "    chat_with_memory,\n",
    "    KernelArguments(input=\"Who are the members of my family?\"),\n",
    "    collection=\"temp\",\n",
    "    limit=3,\n",
    "    min_relevance_score=0.8,\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd0b20-9a22-48d7-96f7-06cd4c6ec38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = await kernel.invoke(\n",
    "    chat_with_memory,\n",
    "    KernelArguments(input=\"How much money have I earned?\"),\n",
    "    collection=\"temp\",\n",
    "    limit=3,\n",
    "    min_relevance_score=0.5,\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dac0e6-4f6a-4d5b-bb40-8eeedade93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = await kernel.invoke(\n",
    "    chat_with_memory,\n",
    "    KernelArguments(input=\"What is ND?\"),\n",
    "    collection=\"temp\",\n",
    "    limit=3,\n",
    "    min_relevance_score=0.5,\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778762bb-86de-4243-bade-b34b9bb5467e",
   "metadata": {},
   "source": [
    "## Plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304932b-8cbf-42f6-8df0-5c902a732b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add plugins\n",
    "text_plugin = kernel.add_plugin(plugin=TextPlugin(), plugin_name=\"TextPlugin\")\n",
    "http_plugin = kernel.add_plugin(plugin=HttpPlugin(), plugin_name=\"HTTPPlugin\")\n",
    "time_plugin = kernel.add_plugin(plugin=TimePlugin(), plugin_name=\"TimePlugin\")\n",
    "math_plugin = kernel.add_plugin(plugin=MathPlugin(), plugin_name=\"MathPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b2a95-2d82-4d16-9e43-8c0b60a16027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view functions\n",
    "plugins_functions = {}\n",
    "for plugin_name, plugin in kernel.plugins.items():\n",
    "    functions = []\n",
    "    for function_name, function in plugin.functions.items():\n",
    "        functions.append(function_name)\n",
    "    plugins_functions[plugin_name] = functions\n",
    "for each_key, each_value in plugins_functions.items():\n",
    "    print(f\"{each_key}: {', '.join(each_value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda0a05-1185-496d-9c22-182c80b73eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function\n",
    "result = await kernel.invoke(plugin_name=\"TimePlugin\", function_name=\"now\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a89e39-a690-458b-8581-946994d3ddb5",
   "metadata": {},
   "source": [
    "## External Plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25adb3c2-59f7-464c-b6b8-760294303223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plugins are prompt-templates saved to the following external files:\n",
    "# ./plugin_name/function_name/config.json <- settings\n",
    "# ./plugin_name/function_name/skprompt.txt <- prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57311d53-6cb3-4fa6-a0c6-bfa62016fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load plugin\n",
    "plugin_functions = kernel.add_plugin(parent_directory=\"./\", plugin_name=\"my_plugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6c619-0af4-4acc-940d-796f0d17a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load function\n",
    "question_function = plugin_functions[\"my_function\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c49e58-578e-4a23-b849-0f4ab5e1a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "result = await kernel.invoke(question_function, input=\"Where was Eddie Van Halen born?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba3777-63c5-4ef9-ba92-a3631b6aac81",
   "metadata": {},
   "source": [
    "## Native Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c3924-43ad-43d6-a93b-71a38b80de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class with functions using @kernel_function decorator\n",
    "class CheckWeatherPlugin:\n",
    "    \"\"\"\n",
    "    Checks the weather\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Checks the weather\",\n",
    "        name=\"CheckWeather\",\n",
    "    )\n",
    "    def check_weather_location(self, location: str) -> str:\n",
    "        \"\"\"\n",
    "        Checks weather\n",
    "        Args:\n",
    "            location: name of city\n",
    "        Returns:\n",
    "            weather\n",
    "        \"\"\"\n",
    "        if location.lower() == \"chicago\":\n",
    "            return \"Sunny and 88 Degrees\"\n",
    "        elif location.lower() == \"new york city\":\n",
    "            return \"Snowing and 20 Degrees\"\n",
    "        else:\n",
    "            return \"I don't know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357614f4-6a8f-4561-ab7f-daa9f3f2853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test functions\n",
    "test_object = CheckWeatherPlugin()\n",
    "print(test_object.check_weather_location(\"chicago\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8f226-bc94-42f9-bdef-b3c278cd905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test native functions\n",
    "check_weather_plugin = kernel.add_plugin(CheckWeatherPlugin(), \"CheckWeatherPlugin\")\n",
    "check_weather_function = check_weather_plugin[\"CheckWeather\"]\n",
    "result = await check_weather_function(kernel, location=\"new york city\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a515c74-4c48-4c2f-a7de-301e0467bcfd",
   "metadata": {},
   "source": [
    "## Auto Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63485532-1703-49e2-8fbf-198a3601842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_prompt = \"\"\"\n",
    "You are a useful chat bot, be as helpful as possible to the user.\n",
    "###CHAT HISTORY###\n",
    "Use the following chat history if useful: {{$history}}\n",
    "User: {{$input}}\n",
    "\"\"\"\n",
    "auto_execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=chat_service_id,\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    function_choice_behavior=FunctionChoiceBehavior.Auto(auto_invoke=True),\n",
    ")\n",
    "auto_execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto(\n",
    "    auto_invoke=True,\n",
    "    filters={\"included_plugins\": [\"CheckWeatherPlugin\"]},\n",
    ")\n",
    "auto_prompt_template_config = PromptTemplateConfig(\n",
    "    template=auto_prompt,\n",
    "    name=\"chat\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"user input\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"conversation history\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=auto_execution_settings,\n",
    ")\n",
    "auto_chat_function = kernel.add_function(\n",
    "    function_name=\"auto_chat\",\n",
    "    plugin_name=\"auto_chatPlugin\",\n",
    "    prompt_template_config=auto_prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54e4f7-63eb-492d-a2fb-dc65a0489e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a163d4-990b-4436-93a4-afdce552032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def auto_chat(input, chat_history):\n",
    "    answer = await kernel.invoke(\n",
    "        auto_chat_function, KernelArguments(input=input, history=chat_history)\n",
    "    )\n",
    "    print(f\"Chatbot: {answer}\")\n",
    "    chat_history.add_user_message(input)\n",
    "    chat_history.add_assistant_message(str(answer))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3749c-abbd-4312-bb37-91a1be2a2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await auto_chat(\"Can you check the weather in Chicago?\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1952d42-7b56-4107-97cb-971fadcc9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await auto_chat(\"Can you check the weather in New York City?\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e93a83-ebd4-4d10-a9fd-990cc056ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await auto_chat(\"Can you check the weather in Hawaii?\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5facaf8-5a96-41ac-8332-0edec7dd1c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
